networks:
  flink_network:
    driver: bridge
    name: flink_network


services:

  kafka-client:
    build: 
      dockerfile: producer_file.dockerfile
    tty : true
    depends_on:
      - kafka
    networks:
      - flink_network
    volumes:
      - ../prod_cons/src:/src
      - ../dataset:/dataset
      - ../Results:/Results
    working_dir : /src
    # command: |
    #         curl -o /Dataset.csv www.ce.uniroma2.it/courses/sabd2223/project/out600_combined+header.csv 


  jobmanager:
    #image: flink:latest
    build:
      dockerfile: ./flink_file.dockerfile
      context: .
    networks:
      - flink_network
    ports:
      - "8081:8081"
    working_dir : /src
    command: | 
            jobmanager
    volumes:
      - ../flink_processor/src:/src
      - ../Results:/Results
    environment:
      - |
        FLINK_PROPERTIES=jobmanager.rpc.address: jobmanager
    tty: true


  taskmanager:
    build:
      dockerfile: flink_file.dockerfile
      context: .
    depends_on:
      - jobmanager
    command: taskmanager
    volumes:
      - ../Results:/Results
      - ../flink_processor/src:/src
    environment:
      - |
        FLINK_PROPERTIES=jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 20
    working_dir : /src
    networks:
      - flink_network  
    tty: true 


  kafka:
    image: 'bitnami/kafka:latest'
    networks:
      - flink_network
    environment:
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true ## To automatically create topic when added events
    tty : true

  
  # spark-master:

  # spark-worker:
  

  ## Redis
  redis :
    image: redis
    networks:
      - flink_network
    ports:
      - "6379:6379"
    tty : true

  # ## Grafana
  # grafana :
  #   image: grafana/grafana
  #   networks:
  #     - my_network
  #   ports:
  #     - "3000:3000"
  #   tty : true


